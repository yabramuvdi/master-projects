{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Forest Cover Using Ensembles of Classifiers\n",
    "\n",
    "### ***Yabra Muvdi***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I try to predict the class of forest cover (the predominant kind of tree cover) from strictly cartographic and environment variables. The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains categorical data for qualitative independent variables (wilderness areas and soil types). The details on the data at *covertype.info* file and at https://archive.ics.uci.edu/ml/datasets/Covertype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import ipywidgets\n",
    "from math import floor, ceil\n",
    "import random\n",
    "import time\n",
    "from utils.helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horiz_dist_hydro</th>\n",
       "      <th>Vertical_dist_hydro</th>\n",
       "      <th>Horiz_dist_roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horiz_dist_firepoints</th>\n",
       "      <th>Cover_Type</th>\n",
       "      <th>Wilderness_Area</th>\n",
       "      <th>Soil_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3202</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2760</td>\n",
       "      <td>219</td>\n",
       "      <td>218</td>\n",
       "      <td>134</td>\n",
       "      <td>1734</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3113</td>\n",
       "      <td>251</td>\n",
       "      <td>13</td>\n",
       "      <td>192</td>\n",
       "      <td>40</td>\n",
       "      <td>5600</td>\n",
       "      <td>191</td>\n",
       "      <td>249</td>\n",
       "      <td>195</td>\n",
       "      <td>2555</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2801</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "      <td>510</td>\n",
       "      <td>17</td>\n",
       "      <td>1728</td>\n",
       "      <td>232</td>\n",
       "      <td>223</td>\n",
       "      <td>122</td>\n",
       "      <td>1087</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3165</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>319</td>\n",
       "      <td>56</td>\n",
       "      <td>4890</td>\n",
       "      <td>233</td>\n",
       "      <td>225</td>\n",
       "      <td>124</td>\n",
       "      <td>1452</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3048</td>\n",
       "      <td>333</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>31</td>\n",
       "      <td>2823</td>\n",
       "      <td>196</td>\n",
       "      <td>226</td>\n",
       "      <td>170</td>\n",
       "      <td>666</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61001</td>\n",
       "      <td>3255</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1552</td>\n",
       "      <td>201</td>\n",
       "      <td>215</td>\n",
       "      <td>151</td>\n",
       "      <td>713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61002</td>\n",
       "      <td>3170</td>\n",
       "      <td>170</td>\n",
       "      <td>25</td>\n",
       "      <td>417</td>\n",
       "      <td>61</td>\n",
       "      <td>2605</td>\n",
       "      <td>229</td>\n",
       "      <td>241</td>\n",
       "      <td>128</td>\n",
       "      <td>3350</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61003</td>\n",
       "      <td>2994</td>\n",
       "      <td>170</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>18</td>\n",
       "      <td>1610</td>\n",
       "      <td>229</td>\n",
       "      <td>245</td>\n",
       "      <td>146</td>\n",
       "      <td>2394</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61004</td>\n",
       "      <td>2543</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>17</td>\n",
       "      <td>524</td>\n",
       "      <td>227</td>\n",
       "      <td>238</td>\n",
       "      <td>145</td>\n",
       "      <td>1106</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61005</td>\n",
       "      <td>2661</td>\n",
       "      <td>213</td>\n",
       "      <td>19</td>\n",
       "      <td>150</td>\n",
       "      <td>-2</td>\n",
       "      <td>2430</td>\n",
       "      <td>199</td>\n",
       "      <td>254</td>\n",
       "      <td>185</td>\n",
       "      <td>1891</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61006 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation  Aspect  Slope  Horiz_dist_hydro  Vertical_dist_hydro  \\\n",
       "0           3202      34     10                 0                    0   \n",
       "1           3113     251     13               192                   40   \n",
       "2           2801      77      9               510                   17   \n",
       "3           3165      82      9               319                   56   \n",
       "4           3048     333     11               124                   31   \n",
       "...          ...     ...    ...               ...                  ...   \n",
       "61001       3255       1     13                 0                    0   \n",
       "61002       3170     170     25               417                   61   \n",
       "61003       2994     170     13               134                   18   \n",
       "61004       2543     135      4               124                   17   \n",
       "61005       2661     213     19               150                   -2   \n",
       "\n",
       "       Horiz_dist_roadways  Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0                     2760            219             218            134   \n",
       "1                     5600            191             249            195   \n",
       "2                     1728            232             223            122   \n",
       "3                     4890            233             225            124   \n",
       "4                     2823            196             226            170   \n",
       "...                    ...            ...             ...            ...   \n",
       "61001                 1552            201             215            151   \n",
       "61002                 2605            229             241            128   \n",
       "61003                 1610            229             245            146   \n",
       "61004                  524            227             238            145   \n",
       "61005                 2430            199             254            185   \n",
       "\n",
       "       Horiz_dist_firepoints  Cover_Type  Wilderness_Area  Soil_Type  \n",
       "0                       1734           1                3         38  \n",
       "1                       2555           2                1         22  \n",
       "2                       1087           2                1         12  \n",
       "3                       1452           1                1         29  \n",
       "4                        666           1                1         23  \n",
       "...                      ...         ...              ...        ...  \n",
       "61001                    713           1                1         38  \n",
       "61002                   3350           2                3         33  \n",
       "61003                   2394           2                3         33  \n",
       "61004                   1106           3                4          6  \n",
       "61005                   1891           2                3         10  \n",
       "\n",
       "[61006 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Data/MultiClass_Train_reduced.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummies(input_file):\n",
    "    \"\"\"This funcion takes an input file, loads its data, separates it into \n",
    "    the variable to predict (Y) and its features (X's) and generates the\n",
    "    required dummy features.\n",
    "    \n",
    "    Warning: This function will only work if the column names in the provided\n",
    "    input file as the same as the ones used for training.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(input_file)\n",
    "    \n",
    "    # Delete rows with missing values\n",
    "    data = data.dropna(axis = 0)\n",
    "    \n",
    "    # Split X's and the Y\n",
    "    y = data[\"Cover_Type\"]  # This is the classificatoin outcome: Class of forest\n",
    "    X = data.drop(['Cover_Type'], axis=1)\n",
    "    \n",
    "    # Preprocessing the features\n",
    "    X_cont = X.drop(['Wilderness_Area', 'Soil_Type'], axis=1)\n",
    "    \n",
    "    wild_dum = pd.get_dummies(X.Wilderness_Area, drop_first = True)\n",
    "    wild_dum.columns = ['Neota','Comanche', 'Cache']\n",
    "    \n",
    "    soil_dum = pd.get_dummies(X.Soil_Type, prefix = \"soil\", drop_first = True)\n",
    "    \n",
    "    X_cat = wild_dum.join(soil_dum)\n",
    "    X_final = X_cont.join(X_cat) \n",
    "    \n",
    "    return X_final, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_dummies(\"./Data/MultiClass_Train_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horiz_dist_hydro</th>\n",
       "      <th>Vertical_dist_hydro</th>\n",
       "      <th>Horiz_dist_roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horiz_dist_firepoints</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_31</th>\n",
       "      <th>soil_32</th>\n",
       "      <th>soil_33</th>\n",
       "      <th>soil_34</th>\n",
       "      <th>soil_35</th>\n",
       "      <th>soil_36</th>\n",
       "      <th>soil_37</th>\n",
       "      <th>soil_38</th>\n",
       "      <th>soil_39</th>\n",
       "      <th>soil_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3202</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2760</td>\n",
       "      <td>219</td>\n",
       "      <td>218</td>\n",
       "      <td>134</td>\n",
       "      <td>1734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3113</td>\n",
       "      <td>251</td>\n",
       "      <td>13</td>\n",
       "      <td>192</td>\n",
       "      <td>40</td>\n",
       "      <td>5600</td>\n",
       "      <td>191</td>\n",
       "      <td>249</td>\n",
       "      <td>195</td>\n",
       "      <td>2555</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2801</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "      <td>510</td>\n",
       "      <td>17</td>\n",
       "      <td>1728</td>\n",
       "      <td>232</td>\n",
       "      <td>223</td>\n",
       "      <td>122</td>\n",
       "      <td>1087</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3165</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>319</td>\n",
       "      <td>56</td>\n",
       "      <td>4890</td>\n",
       "      <td>233</td>\n",
       "      <td>225</td>\n",
       "      <td>124</td>\n",
       "      <td>1452</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3048</td>\n",
       "      <td>333</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>31</td>\n",
       "      <td>2823</td>\n",
       "      <td>196</td>\n",
       "      <td>226</td>\n",
       "      <td>170</td>\n",
       "      <td>666</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61001</td>\n",
       "      <td>3255</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1552</td>\n",
       "      <td>201</td>\n",
       "      <td>215</td>\n",
       "      <td>151</td>\n",
       "      <td>713</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61002</td>\n",
       "      <td>3170</td>\n",
       "      <td>170</td>\n",
       "      <td>25</td>\n",
       "      <td>417</td>\n",
       "      <td>61</td>\n",
       "      <td>2605</td>\n",
       "      <td>229</td>\n",
       "      <td>241</td>\n",
       "      <td>128</td>\n",
       "      <td>3350</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61003</td>\n",
       "      <td>2994</td>\n",
       "      <td>170</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "      <td>18</td>\n",
       "      <td>1610</td>\n",
       "      <td>229</td>\n",
       "      <td>245</td>\n",
       "      <td>146</td>\n",
       "      <td>2394</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61004</td>\n",
       "      <td>2543</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "      <td>17</td>\n",
       "      <td>524</td>\n",
       "      <td>227</td>\n",
       "      <td>238</td>\n",
       "      <td>145</td>\n",
       "      <td>1106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61005</td>\n",
       "      <td>2661</td>\n",
       "      <td>213</td>\n",
       "      <td>19</td>\n",
       "      <td>150</td>\n",
       "      <td>-2</td>\n",
       "      <td>2430</td>\n",
       "      <td>199</td>\n",
       "      <td>254</td>\n",
       "      <td>185</td>\n",
       "      <td>1891</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61006 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation  Aspect  Slope  Horiz_dist_hydro  Vertical_dist_hydro  \\\n",
       "0           3202      34     10                 0                    0   \n",
       "1           3113     251     13               192                   40   \n",
       "2           2801      77      9               510                   17   \n",
       "3           3165      82      9               319                   56   \n",
       "4           3048     333     11               124                   31   \n",
       "...          ...     ...    ...               ...                  ...   \n",
       "61001       3255       1     13                 0                    0   \n",
       "61002       3170     170     25               417                   61   \n",
       "61003       2994     170     13               134                   18   \n",
       "61004       2543     135      4               124                   17   \n",
       "61005       2661     213     19               150                   -2   \n",
       "\n",
       "       Horiz_dist_roadways  Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0                     2760            219             218            134   \n",
       "1                     5600            191             249            195   \n",
       "2                     1728            232             223            122   \n",
       "3                     4890            233             225            124   \n",
       "4                     2823            196             226            170   \n",
       "...                    ...            ...             ...            ...   \n",
       "61001                 1552            201             215            151   \n",
       "61002                 2605            229             241            128   \n",
       "61003                 1610            229             245            146   \n",
       "61004                  524            227             238            145   \n",
       "61005                 2430            199             254            185   \n",
       "\n",
       "       Horiz_dist_firepoints  ...  soil_31  soil_32  soil_33  soil_34  \\\n",
       "0                       1734  ...        0        0        0        0   \n",
       "1                       2555  ...        0        0        0        0   \n",
       "2                       1087  ...        0        0        0        0   \n",
       "3                       1452  ...        0        0        0        0   \n",
       "4                        666  ...        0        0        0        0   \n",
       "...                      ...  ...      ...      ...      ...      ...   \n",
       "61001                    713  ...        0        0        0        0   \n",
       "61002                   3350  ...        0        0        1        0   \n",
       "61003                   2394  ...        0        0        1        0   \n",
       "61004                   1106  ...        0        0        0        0   \n",
       "61005                   1891  ...        0        0        0        0   \n",
       "\n",
       "       soil_35  soil_36  soil_37  soil_38  soil_39  soil_40  \n",
       "0            0        0        0        1        0        0  \n",
       "1            0        0        0        0        0        0  \n",
       "2            0        0        0        0        0        0  \n",
       "3            0        0        0        0        0        0  \n",
       "4            0        0        0        0        0        0  \n",
       "...        ...      ...      ...      ...      ...      ...  \n",
       "61001        0        0        0        1        0        0  \n",
       "61002        0        0        0        0        0        0  \n",
       "61003        0        0        0        0        0        0  \n",
       "61004        0        0        0        0        0        0  \n",
       "61005        0        0        0        0        0        0  \n",
       "\n",
       "[61006 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        2\n",
       "2        2\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "61001    1\n",
       "61002    2\n",
       "61003    2\n",
       "61004    3\n",
       "61005    2\n",
       "Name: Cover_Type, Length: 61006, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should create a **y** variable that only shows if a forest is class 2 or 3 (or if it is not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_23 = np.where((y == 2) | (y==3), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33492"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_23.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = pd.get_dummies(y)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = pd.get_dummies(y)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33492"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2.sum() + y3.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_23_train = np.where((y_train == 2) | (y_train == 3), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_23_test = np.where((y_test == 2) | (y_test == 3), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceding any further we should rescale our features in order to for them to have a commom mean and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to save this object 'scaler' because I want to use the same one for both the training and the test data\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "X_train=pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test=pd.DataFrame(X_test, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horiz_dist_hydro</th>\n",
       "      <th>Vertical_dist_hydro</th>\n",
       "      <th>Horiz_dist_roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horiz_dist_firepoints</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_31</th>\n",
       "      <th>soil_32</th>\n",
       "      <th>soil_33</th>\n",
       "      <th>soil_34</th>\n",
       "      <th>soil_35</th>\n",
       "      <th>soil_36</th>\n",
       "      <th>soil_37</th>\n",
       "      <th>soil_38</th>\n",
       "      <th>soil_39</th>\n",
       "      <th>soil_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "      <td>4.575400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-7.345515e-16</td>\n",
       "      <td>-2.981689e-17</td>\n",
       "      <td>3.785348e-17</td>\n",
       "      <td>-6.988334e-17</td>\n",
       "      <td>-1.894615e-17</td>\n",
       "      <td>-1.188017e-16</td>\n",
       "      <td>4.391780e-16</td>\n",
       "      <td>2.338762e-16</td>\n",
       "      <td>-3.135432e-16</td>\n",
       "      <td>2.329445e-19</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.795334e-17</td>\n",
       "      <td>7.578460e-17</td>\n",
       "      <td>4.565712e-17</td>\n",
       "      <td>-4.379356e-17</td>\n",
       "      <td>4.503593e-18</td>\n",
       "      <td>-6.211852e-18</td>\n",
       "      <td>4.658889e-18</td>\n",
       "      <td>-5.155837e-17</td>\n",
       "      <td>1.708259e-17</td>\n",
       "      <td>5.093719e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "      <td>1.000011e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-3.857424e+00</td>\n",
       "      <td>-1.392601e+00</td>\n",
       "      <td>-1.884201e+00</td>\n",
       "      <td>-1.269371e+00</td>\n",
       "      <td>-3.437989e+00</td>\n",
       "      <td>-1.505327e+00</td>\n",
       "      <td>-5.718100e+00</td>\n",
       "      <td>-7.114132e+00</td>\n",
       "      <td>-3.717809e+00</td>\n",
       "      <td>-1.504321e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.141902e-01</td>\n",
       "      <td>-3.152880e-01</td>\n",
       "      <td>-2.908669e-01</td>\n",
       "      <td>-5.579620e-02</td>\n",
       "      <td>-5.419694e-02</td>\n",
       "      <td>-1.322417e-02</td>\n",
       "      <td>-1.870344e-02</td>\n",
       "      <td>-1.641146e-01</td>\n",
       "      <td>-1.584076e-01</td>\n",
       "      <td>-1.210727e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-5.366756e-01</td>\n",
       "      <td>-8.663449e-01</td>\n",
       "      <td>-6.853951e-01</td>\n",
       "      <td>-7.582694e-01</td>\n",
       "      <td>-6.771781e-01</td>\n",
       "      <td>-7.990982e-01</td>\n",
       "      <td>-5.207036e-01</td>\n",
       "      <td>-5.129665e-01</td>\n",
       "      <td>-6.133576e-01</td>\n",
       "      <td>-7.196235e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.141902e-01</td>\n",
       "      <td>-3.152880e-01</td>\n",
       "      <td>-2.908669e-01</td>\n",
       "      <td>-5.579620e-02</td>\n",
       "      <td>-5.419694e-02</td>\n",
       "      <td>-1.322417e-02</td>\n",
       "      <td>-1.870344e-02</td>\n",
       "      <td>-1.641146e-01</td>\n",
       "      <td>-1.584076e-01</td>\n",
       "      <td>-1.210727e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.360162e-01</td>\n",
       "      <td>-2.598128e-01</td>\n",
       "      <td>-1.525924e-01</td>\n",
       "      <td>-2.377028e-01</td>\n",
       "      <td>-2.827765e-01</td>\n",
       "      <td>-2.314207e-01</td>\n",
       "      <td>2.217816e-01</td>\n",
       "      <td>1.421110e-01</td>\n",
       "      <td>1.275027e-02</td>\n",
       "      <td>-2.013123e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.141902e-01</td>\n",
       "      <td>-3.152880e-01</td>\n",
       "      <td>-2.908669e-01</td>\n",
       "      <td>-5.579620e-02</td>\n",
       "      <td>-5.419694e-02</td>\n",
       "      <td>-1.322417e-02</td>\n",
       "      <td>-1.870344e-02</td>\n",
       "      <td>-1.641146e-01</td>\n",
       "      <td>-1.584076e-01</td>\n",
       "      <td>-1.210727e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.268461e-01</td>\n",
       "      <td>9.443318e-01</td>\n",
       "      <td>5.134110e-01</td>\n",
       "      <td>5.384147e-01</td>\n",
       "      <td>3.859914e-01</td>\n",
       "      <td>6.236234e-01</td>\n",
       "      <td>7.043970e-01</td>\n",
       "      <td>6.964074e-01</td>\n",
       "      <td>6.910338e-01</td>\n",
       "      <td>4.364920e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.141902e-01</td>\n",
       "      <td>-3.152880e-01</td>\n",
       "      <td>-2.908669e-01</td>\n",
       "      <td>-5.579620e-02</td>\n",
       "      <td>-5.419694e-02</td>\n",
       "      <td>-1.322417e-02</td>\n",
       "      <td>-1.870344e-02</td>\n",
       "      <td>-1.641146e-01</td>\n",
       "      <td>-1.584076e-01</td>\n",
       "      <td>-1.210727e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.161350e+00</td>\n",
       "      <td>1.818452e+00</td>\n",
       "      <td>5.175435e+00</td>\n",
       "      <td>5.308698e+00</td>\n",
       "      <td>9.354341e+00</td>\n",
       "      <td>3.037375e+00</td>\n",
       "      <td>1.558255e+00</td>\n",
       "      <td>1.553047e+00</td>\n",
       "      <td>2.856324e+00</td>\n",
       "      <td>3.907883e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.668748e+00</td>\n",
       "      <td>3.171704e+00</td>\n",
       "      <td>3.437999e+00</td>\n",
       "      <td>1.792237e+01</td>\n",
       "      <td>1.845123e+01</td>\n",
       "      <td>7.561911e+01</td>\n",
       "      <td>5.346611e+01</td>\n",
       "      <td>6.093302e+00</td>\n",
       "      <td>6.312827e+00</td>\n",
       "      <td>8.259501e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Elevation        Aspect         Slope  Horiz_dist_hydro  \\\n",
       "count  4.575400e+04  4.575400e+04  4.575400e+04      4.575400e+04   \n",
       "mean  -7.345515e-16 -2.981689e-17  3.785348e-17     -6.988334e-17   \n",
       "std    1.000011e+00  1.000011e+00  1.000011e+00      1.000011e+00   \n",
       "min   -3.857424e+00 -1.392601e+00 -1.884201e+00     -1.269371e+00   \n",
       "25%   -5.366756e-01 -8.663449e-01 -6.853951e-01     -7.582694e-01   \n",
       "50%    1.360162e-01 -2.598128e-01 -1.525924e-01     -2.377028e-01   \n",
       "75%    7.268461e-01  9.443318e-01  5.134110e-01      5.384147e-01   \n",
       "max    3.161350e+00  1.818452e+00  5.175435e+00      5.308698e+00   \n",
       "\n",
       "       Vertical_dist_hydro  Horiz_dist_roadways  Hillshade_9am  \\\n",
       "count         4.575400e+04         4.575400e+04   4.575400e+04   \n",
       "mean         -1.894615e-17        -1.188017e-16   4.391780e-16   \n",
       "std           1.000011e+00         1.000011e+00   1.000011e+00   \n",
       "min          -3.437989e+00        -1.505327e+00  -5.718100e+00   \n",
       "25%          -6.771781e-01        -7.990982e-01  -5.207036e-01   \n",
       "50%          -2.827765e-01        -2.314207e-01   2.217816e-01   \n",
       "75%           3.859914e-01         6.236234e-01   7.043970e-01   \n",
       "max           9.354341e+00         3.037375e+00   1.558255e+00   \n",
       "\n",
       "       Hillshade_Noon  Hillshade_3pm  Horiz_dist_firepoints  ...  \\\n",
       "count    4.575400e+04   4.575400e+04           4.575400e+04  ...   \n",
       "mean     2.338762e-16  -3.135432e-16           2.329445e-19  ...   \n",
       "std      1.000011e+00   1.000011e+00           1.000011e+00  ...   \n",
       "min     -7.114132e+00  -3.717809e+00          -1.504321e+00  ...   \n",
       "25%     -5.129665e-01  -6.133576e-01          -7.196235e-01  ...   \n",
       "50%      1.421110e-01   1.275027e-02          -2.013123e-01  ...   \n",
       "75%      6.964074e-01   6.910338e-01           4.364920e-01  ...   \n",
       "max      1.553047e+00   2.856324e+00           3.907883e+00  ...   \n",
       "\n",
       "            soil_31       soil_32       soil_33       soil_34       soil_35  \\\n",
       "count  4.575400e+04  4.575400e+04  4.575400e+04  4.575400e+04  4.575400e+04   \n",
       "mean  -2.795334e-17  7.578460e-17  4.565712e-17 -4.379356e-17  4.503593e-18   \n",
       "std    1.000011e+00  1.000011e+00  1.000011e+00  1.000011e+00  1.000011e+00   \n",
       "min   -2.141902e-01 -3.152880e-01 -2.908669e-01 -5.579620e-02 -5.419694e-02   \n",
       "25%   -2.141902e-01 -3.152880e-01 -2.908669e-01 -5.579620e-02 -5.419694e-02   \n",
       "50%   -2.141902e-01 -3.152880e-01 -2.908669e-01 -5.579620e-02 -5.419694e-02   \n",
       "75%   -2.141902e-01 -3.152880e-01 -2.908669e-01 -5.579620e-02 -5.419694e-02   \n",
       "max    4.668748e+00  3.171704e+00  3.437999e+00  1.792237e+01  1.845123e+01   \n",
       "\n",
       "            soil_36       soil_37       soil_38       soil_39       soil_40  \n",
       "count  4.575400e+04  4.575400e+04  4.575400e+04  4.575400e+04  4.575400e+04  \n",
       "mean  -6.211852e-18  4.658889e-18 -5.155837e-17  1.708259e-17  5.093719e-17  \n",
       "std    1.000011e+00  1.000011e+00  1.000011e+00  1.000011e+00  1.000011e+00  \n",
       "min   -1.322417e-02 -1.870344e-02 -1.641146e-01 -1.584076e-01 -1.210727e-01  \n",
       "25%   -1.322417e-02 -1.870344e-02 -1.641146e-01 -1.584076e-01 -1.210727e-01  \n",
       "50%   -1.322417e-02 -1.870344e-02 -1.641146e-01 -1.584076e-01 -1.210727e-01  \n",
       "75%   -1.322417e-02 -1.870344e-02 -1.641146e-01 -1.584076e-01 -1.210727e-01  \n",
       "max    7.561911e+01  5.346611e+01  6.093302e+00  6.312827e+00  8.259501e+00  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build Binary Classification Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load K-NN from sklearn\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier \n",
    "#Initialize model\n",
    "KNN = KNeighborsClassifier(n_neighbors = 10, weights = 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(X_train, y_23_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(C=100, random_state= 92, solver='lbfgs', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=92, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train, y_23_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=20, max_leaf_nodes = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=50,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_23_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Ensembling models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary with my models\n",
    "models = {'logistic': logistic,\n",
    "              'knn': KNN,\n",
    "              'random forest': forest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=92, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'knn': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                      metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                      weights='distance'),\n",
       " 'random forest': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=50,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model_list,xtrain = X_train,ytrain= y_23_train,xtest=X_test,ytest=y_23_test):\n",
    "    #Fit models in list on training set and return preds\n",
    "    P = np.zeros((ytest.shape[0], len(model_list)))\n",
    "    P = pd.DataFrame(P)\n",
    "\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        #m.fit(xtrain, ytrain)\n",
    "        P.iloc[:, i] = m.predict_proba(xtest)[:, 1]\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "\n",
    "    P.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P\n",
    "\n",
    "\n",
    "def score_models(P, y):\n",
    "    # Score model in test set\n",
    "    print(\"Scoring models.\")\n",
    "    scores=[]\n",
    "    for m in P.columns:\n",
    "        score = roc_auc_score(y, P.loc[:, m])\n",
    "        scores.append(score)\n",
    "        print(\"%-26s: %.3f\" % (m, score))\n",
    "    return P.columns,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic... done\n",
      "knn... done\n",
      "random forest... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "logistic                  : 0.820\n",
      "knn                       : 0.941\n",
      "random forest             : 0.846\n"
     ]
    }
   ],
   "source": [
    "#Get some first scores and predictions from the simple models\n",
    "P = train_predict(models,X_train,y_23_train,X_test,y_23_test)\n",
    "my_models,my_scores= score_models(P, y_23_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Meta-learner\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "meta_learner = ExtraTreesClassifier(\n",
    "    n_estimators=10,\n",
    "    bootstrap=True,\n",
    "    max_features=0.7,\n",
    "    random_state=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=92, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='distance'), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=50,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer-1             done | 00:02:48\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:02:49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=5,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4218, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=5, raise_on_ex...rer=None)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=92, sample_size=20, scorer=None, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlens\n",
    "from mlens.ensemble import SuperLearner\n",
    "# Instantiate the ensemble\n",
    "sl = SuperLearner(\n",
    "    folds=5,\n",
    "    random_state=92,\n",
    "    verbose=2,\n",
    "    backend=\"multiprocessing\"\n",
    ")\n",
    "\n",
    "# Add the base learners and the meta learner\n",
    "sl.add(list(models.values()), proba=True)\n",
    "sl.add_meta(meta_learner, proba=True)\n",
    "\n",
    "# Train the ensemble\n",
    "sl.fit(X_train, y_23_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:01:12\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:01:13\n",
      "\n",
      "Super Learner ROC-AUC score: 0.915\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "p_sl = sl.predict_proba(X_test)\n",
    "scoreStack1 = roc_auc_score(y_23_test, p_sl[:, 1])\n",
    "print(\"\\nSuper Learner ROC-AUC score: %.3f\" % scoreStack1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=5,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=4218, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=5, raise_on_ex...rer=None)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=92, sample_size=20, scorer=None, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
